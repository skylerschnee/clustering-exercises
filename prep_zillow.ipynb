{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b63de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_outliers(df,feature_list):\n",
    "    ''' utilizes IQR to remove data which lies beyond \n",
    "    three standard deviations of the mean\n",
    "    '''\n",
    "    for feature in feature_list:\n",
    "    \n",
    "        #define interquartile range\n",
    "        Q1= df[feature].quantile(0.25)\n",
    "        Q3 = df[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        #Set limits\n",
    "        upper_limit = Q3 + 3 * IQR\n",
    "        lower_limit = Q1 - 3 * IQR\n",
    "        #remove outliers\n",
    "        df = df[(df[feature] > lower_limit) & (df[feature] < upper_limit)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def fill_null_with_corresponding_value(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Fills null values in column2 with corresponding non-null values from column1 in a pandas DataFrame\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()  # make a copy of the original dataframe to avoid modifying it\n",
    "    df_copy[col2].fillna(df_copy[col1], inplace=True)  # fill null values in column2 with corresponding values from column1\n",
    "    return df_copy\n",
    "\n",
    "def mean_impute_columns(df, column_names):\n",
    "    \"\"\"\n",
    "    Applies mode imputation to fill null values in specific columns of a pandas DataFrame\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        mean_value = df[column_name].mean()\n",
    "        df[column_name].fillna(mean_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "def mode_impute_columns(df, column_names):\n",
    "    \"\"\"\n",
    "    Applies mode imputation to fill null values in specific columns of a pandas DataFrame\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        mode_value = df[column_name].mode().iloc[0]\n",
    "        df[column_name].fillna(mode_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_object_dtype(df, columns):\n",
    "    \"\"\"\n",
    "    Convert specified columns in a pandas DataFrame to object dtype\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('object')\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_zillow(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # isolate property type as single family\n",
    "    df = df[df.propertylandusetypeid == (261 or 279)]\n",
    "    # remove multi unit properties\n",
    "    df = df[df.unitcnt == 1]\n",
    "    # identify features to remove outliers\n",
    "    feature_list = ['bathroomcnt', 'bedroomcnt', 'calculatedbathnbr', 'calculatedfinishedsquarefeet',\n",
    "               'finishedsquarefeet12', 'fullbathcnt', 'lotsizesquarefeet', 'rawcensustractandblock', \n",
    "               'roomcnt', 'unitcnt', 'yearbuilt','assessmentyear','landtaxvaluedollarcnt', \n",
    "               'taxamount', 'censustractandblock']\n",
    "    # rmove outliers\n",
    "    remove_outliers(df,feature_list)\n",
    "    # call function to fill nulls\n",
    "    df = fill_null_with_corresponding_value(df, col1='rawcensustractandblock', col2='censustractandblock')\n",
    "    # identify redundant or unuseful cols\n",
    "    cols_to_drop = ['id','parcelid','calculatedbathnbr','finishedsquarefeet12',\n",
    "                'fullbathcnt','unitcnt','rawcensustractandblock','propertyzoningdesc',\n",
    "                'regionidcity','heatingorsystemtypeid', 'propertylandusetypeid', \n",
    "                'regionidzip', 'assessmentyear', 'propertylandusedesc', \n",
    "                'regionidcounty', 'roomcnt']\n",
    "    # drop them\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    # identify cols to impute nulls with mean\n",
    "    cols_to_impute_mean = ['lotsizesquarefeet','structuretaxvaluedollarcnt', 'yearbuilt']\n",
    "    # impute them\n",
    "    df = mean_impute_columns(df, column_names=cols_to_impute_mean)\n",
    "    # identify cols to impute with mode\n",
    "    cols_to_impute_mode = ['buildingqualitytypeid','heatingorsystemdesc']\n",
    "    # impute them\n",
    "    df = mode_impute_columns(df, column_names=cols_to_impute_mode)\n",
    "    # dop remaining nulls (2 of them)\n",
    "    df = df.dropna()\n",
    "    # identify cols we want as objects\n",
    "    cols_to_obj = ['fips','hvac_type', 'propertylandusedesc','buildingqualitytypeid']\n",
    "    # convert them by calling function\n",
    "    df = convert_to_object_dtype(df, columns = cols_to_obj)\n",
    "    #rename cols to promote readability\n",
    "    df = df.rename(columns={'bathroomcnt': 'bathrooms', 'bedroomcnt': 'bedrooms', \n",
    "                        'buildingqualitytypeid': 'quality_id', 'calculatedfinishedsquarefeet': 'sqft',\n",
    "                        'fips': 'county', 'lotsizesquarefeet': 'lot_sqft',\n",
    "                        'propertycountylandusecode': 'prop_use_code', 'yearbuilt': 'year_built',\n",
    "                        'structuretaxvaluedollarcnt': 'structure_value', 'taxvaluedollarcnt': 'home_value',\n",
    "                        'censustractandblock': 'tract&block', 'transactiondate': 'txn_date',\n",
    "                        'heatingorsystemdesc': 'hvac_type', 'landtaxvaluedollarcnt': 'land_value'})\n",
    "    # convert fip code to county name\n",
    "    df['county'] = df['county'].replace({6037.0: 'los_angeles', 6059.0: 'orange', 6111.0: 'ventura'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def split_zillow(df):\n",
    "    '''\n",
    "    split_zillow will take in a single pandas df referencing a cleaned\n",
    "    version of zillow data, and will then split the data into train,\n",
    "    validate, and test sets stratifying on home_value\n",
    "    \n",
    "    Arguments: df. a pandas dataframe\n",
    "    return: train, validate, test: the pandas df split from orginal df \n",
    "    '''\n",
    "    train_val, test = train_test_split(df, random_state = 828, train_size = 0.8)\n",
    "    train, validate = train_test_split(train_val, random_state = 828, train_size = 0.7)\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "def scale_zillow(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #identify features to scale\n",
    "    feats_to_scale = ['bathrooms', 'bedrooms', 'sqft','lot_sqft', 'year_built',\n",
    "                  'structure_value', 'home_value', 'land_value', 'taxamount']\n",
    "    #for loop to name new scaled cols\n",
    "    cols_scaled = [col + '_scaled' for col in feats_to_scale]\n",
    "    # scale and transform\n",
    "    df[cols_scaled] = MinMaxScaler().fit_transform(df[feats_to_scale])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
